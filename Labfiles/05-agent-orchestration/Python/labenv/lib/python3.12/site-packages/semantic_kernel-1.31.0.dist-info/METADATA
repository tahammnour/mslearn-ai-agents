Metadata-Version: 2.4
Name: semantic-kernel
Version: 1.31.0
Summary: Semantic Kernel Python SDK
Author-email: Microsoft <SK-Support@microsoft.com>
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Classifier: License :: OSI Approved :: MIT License
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Framework :: Pydantic :: 2
Classifier: Typing :: Typed
License-File: LICENSE
Requires-Dist: aiohttp ~= 3.8
Requires-Dist: cloudevents ~=1.0
Requires-Dist: pydantic >=2.0,!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12
Requires-Dist: pydantic-settings ~= 2.0
Requires-Dist: defusedxml ~= 0.7
Requires-Dist: azure-identity >= 1.13
Requires-Dist: numpy >= 1.25.0; python_version < '3.12'
Requires-Dist: numpy >= 1.26.0; python_version >= '3.12'
Requires-Dist: openai >= 1.67
Requires-Dist: openapi_core >= 0.18,<0.20
Requires-Dist: websockets >= 13, < 16
Requires-Dist: aiortc>=1.9.0
Requires-Dist: opentelemetry-api ~= 1.24
Requires-Dist: opentelemetry-sdk ~= 1.24
Requires-Dist: prance >= 23.6.21,< 25.4.9
Requires-Dist: pybars4 ~= 0.9
Requires-Dist: jinja2 ~= 3.1
Requires-Dist: nest-asyncio ~= 1.6
Requires-Dist: scipy>=1.15.1
Requires-Dist: websockets >= 13, < 16
Requires-Dist: aiortc>=1.9.0
Requires-Dist: protobuf
Requires-Dist: typing-extensions>=4.13
Requires-Dist: anthropic ~= 0.32 ; extra == "anthropic"
Requires-Dist: autogen-agentchat >= 0.2, <0.4 ; extra == "autogen"
Requires-Dist: boto3>=1.36.4,<1.39.0 ; extra == "aws"
Requires-Dist: azure-ai-projects >= 1.0.0b11 ; extra == "azure"
Requires-Dist: azure-ai-agents >= 1.0.0 ; extra == "azure"
Requires-Dist: azure-ai-inference >= 1.0.0b6 ; extra == "azure"
Requires-Dist: azure-core-tracing-opentelemetry >= 1.0.0b11 ; extra == "azure"
Requires-Dist: azure-search-documents >= 11.6.0b4 ; extra == "azure"
Requires-Dist: azure-cosmos ~= 4.7 ; extra == "azure"
Requires-Dist: chromadb >= 0.5,< 1.1 ; extra == "chroma"
Requires-Dist: dapr>=1.14.0 ; extra == "dapr"
Requires-Dist: dapr-ext-fastapi>=1.14.0 ; extra == "dapr"
Requires-Dist: flask-dapr>=1.14.0 ; extra == "dapr"
Requires-Dist: faiss-cpu>=1.10.0 ; extra == "faiss"
Requires-Dist: google-cloud-aiplatform == 1.91.0 ; extra == "google"
Requires-Dist: google-generativeai ~= 0.8 ; extra == "google"
Requires-Dist: transformers[torch] ~= 4.28 ; extra == "hugging-face"
Requires-Dist: sentence-transformers >= 2.2,< 5.0 ; extra == "hugging-face"
Requires-Dist: torch == 2.7.0 ; extra == "hugging-face"
Requires-Dist: mcp>=1.8 ; extra == "mcp"
Requires-Dist: pymilvus >= 2.3,< 2.6 ; extra == "milvus"
Requires-Dist: milvus >= 2.3,<2.3.8 ; extra == "milvus" and ( platform_system != 'Windows')
Requires-Dist: mistralai >= 1.2,< 2.0 ; extra == "mistralai"
Requires-Dist: pymongo >= 4.8.0, < 4.13 ; extra == "mongo"
Requires-Dist: motor >= 3.3.2,< 3.8.0 ; extra == "mongo"
Requires-Dist: ipykernel ~= 6.29 ; extra == "notebooks"
Requires-Dist: ollama ~= 0.4 ; extra == "ollama"
Requires-Dist: onnxruntime-genai ~= 0.5 ; extra == "onnx" and ( python_version < '3.13' and platform_system != 'Windows')
Requires-Dist: onnxruntime == 1.21.0 ; extra == "onnx" and ( platform_system == 'Windows')
Requires-Dist: pandas ~= 2.2 ; extra == "pandas"
Requires-Dist: pinecone[asyncio, grpc] ~= 6.0 ; extra == "pinecone"
Requires-Dist: psycopg[binary, pool] ~= 3.2 ; extra == "postgres"
Requires-Dist: qdrant-client ~= 1.9 ; extra == "qdrant"
Requires-Dist: websockets >= 13, < 16 ; extra == "realtime"
Requires-Dist: aiortc>=1.9.0 ; extra == "realtime"
Requires-Dist: redis[hiredis] ~= 5.0 ; extra == "redis"
Requires-Dist: types-redis ~= 4.6.0.20240425 ; extra == "redis"
Requires-Dist: redisvl ~= 0.4 ; extra == "redis"
Requires-Dist: pyodbc >= 5.2 ; extra == "sql"
Requires-Dist: usearch ~= 2.16 ; extra == "usearch"
Requires-Dist: pyarrow >= 12.0,< 21.0 ; extra == "usearch"
Requires-Dist: weaviate-client>=4.10,<5.0 ; extra == "weaviate"
Project-URL: homepage, https://learn.microsoft.com/en-us/semantic-kernel/overview/
Project-URL: issues, https://github.com/microsoft/semantic-kernel/issues
Project-URL: release_notes, https://github.com/microsoft/semantic-kernel/releases?q=tag%3Apython-1&expanded=true
Project-URL: source, https://github.com/microsoft/semantic-kernel/tree/main/python
Provides-Extra: anthropic
Provides-Extra: autogen
Provides-Extra: aws
Provides-Extra: azure
Provides-Extra: chroma
Provides-Extra: dapr
Provides-Extra: faiss
Provides-Extra: google
Provides-Extra: hugging-face
Provides-Extra: mcp
Provides-Extra: milvus
Provides-Extra: mistralai
Provides-Extra: mongo
Provides-Extra: notebooks
Provides-Extra: ollama
Provides-Extra: onnx
Provides-Extra: pandas
Provides-Extra: pinecone
Provides-Extra: postgres
Provides-Extra: qdrant
Provides-Extra: realtime
Provides-Extra: redis
Provides-Extra: sql
Provides-Extra: usearch
Provides-Extra: weaviate

# Get Started with Semantic Kernel âš¡

Install the latest package:
```bash
python -m pip install --upgrade semantic-kernel
```
If you want to use some of the optional dependencies (OpenAI is installed by default), you can install them with:
```bash
python -m pip install --upgrade semantic-kernel[hugging_face]
```

or all of them:
```bash
python -m pip install --upgrade semantic-kernel[all]
```
# AI Services

## OpenAI / Azure OpenAI API keys

Make sure you have an
[OpenAI API Key](https://platform.openai.com/) or
[Azure OpenAI service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=rest-api)

There are two methods to manage keys, secrets, and endpoints:

1. Store them in environment variables. SK Python leverages Pydantic settings to load keys, secrets, and endpoints. This means that there is a first attempt to load them from environment variables. The `.env` file naming applies to how the names should be stored as environment variables.

2. If you'd like to use the `.env` file, you will need to configure the `.env` file with the following keys in the file (see the `.env.example` file):

```bash
OPENAI_API_KEY=""
OPENAI_ORG_ID=""
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=""
AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=""
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=""
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_KEY=""
```

Put the .env file in the root directory.

If you place the .env in a different directory, configure the Text/ChatCompletion class with the keyword argument `env_file_path`:

```python
chat_completion = OpenAIChatCompletion(service_id="test", env_file_path=<path_to_file>)
```

This optional `env_file_path` parameter will allow pydantic settings to use the `.env` file as a fallback to read the settings.

# Running a prompt

```python
import asyncio
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, AzureChatCompletion
from semantic_kernel.prompt_template import PromptTemplateConfig

kernel = Kernel()

# Prepare OpenAI service using credentials stored in the `.env` file
service_id="chat-gpt"
kernel.add_service(
    OpenAIChatCompletion(
        service_id=service_id,
    )
)

# Alternative using Azure:
# kernel.add_service(
#   AzureChatCompletion(
#       service_id=service_id,
#   )
# )

# Define the request settings
req_settings = kernel.get_prompt_execution_settings_from_service_id(service_id)
req_settings.max_tokens = 2000
req_settings.temperature = 0.7
req_settings.top_p = 0.8

prompt = """
1) A robot may not injure a human being or, through inaction,
allow a human being to come to harm.

2) A robot must obey orders given it by human beings except where
such orders would conflict with the First Law.

3) A robot must protect its own existence as long as such protection
does not conflict with the First or Second Law.

Give me the TLDR in exactly 5 words."""

prompt_template_config = PromptTemplateConfig(
    template=prompt,
    name="tldr",
    template_format="semantic-kernel",
    execution_settings=req_settings,
)

function = kernel.add_function(
    function_name="tldr_function",
    plugin_name="tldr_plugin",
    prompt_template_config=prompt_template_config,
)

# Run your prompt
# Note: functions are run asynchronously
async def main():
    result = await kernel.invoke(function)
    print(result) # => Robots must not harm humans.

if __name__ == "__main__":
    asyncio.run(main())
# If running from a jupyter-notebook:
# await main()
```

# **Semantic Prompt Functions** are Prompts with input parameters

```python
# Create a reusable function summarize function
summarize = kernel.add_function(
    function_name="tldr_function",
    plugin_name="tldr_plugin",
    prompt="{{$input}}\n\nOne line TLDR with the fewest words.",
    prompt_execution_settings=req_settings,
)

# Summarize the laws of thermodynamics
print(await kernel.invoke(summarize, input="""
1st Law of Thermodynamics - Energy cannot be created or destroyed.
2nd Law of Thermodynamics - For a spontaneous process, the entropy of the universe increases.
3rd Law of Thermodynamics - A perfect crystal at zero Kelvin has zero entropy."""))

# Summarize the laws of motion
print(await kernel.invoke(summarize, input="""
1. An object at rest remains at rest, and an object in motion remains in motion at constant speed and in a straight line unless acted on by an unbalanced force.
2. The acceleration of an object depends on the mass of the object and the amount of force applied.
3. Whenever one object exerts a force on another object, the second object exerts an equal and opposite on the first."""))

# Summarize the law of universal gravitation
print(await kernel.invoke(summarize, input="""
Every point mass attracts every single other point mass by a force acting along the line intersecting both points.
The force is proportional to the product of the two masses and inversely proportional to the square of the distance between them."""))

# Output:
# > Energy conserved, entropy increases, zero entropy at 0K.
# > Objects move in response to forces.
# > Gravitational force between two point masses is inversely proportional to the square of the distance between them.
```

# Semantic Kernel Notebooks

The repository contains a few Python and C# notebooks that demonstrate how to
get started with the Semantic Kernel.

Python notebooks:

- [Getting started with Semantic Kernel](./samples/getting_started/00-getting-started.ipynb)
- [Loading and configuring Semantic Kernel](./samples/getting_started/01-basic-loading-the-kernel.ipynb)
- [Running AI prompts from file](./samples/getting_started/02-running-prompts-from-file.ipynb)
- [Creating Prompt Functions at runtime (i.e. inline functions)](./samples/getting_started/03-prompt-function-inline.ipynb)
- [Using Context Variables to Build a Chat Experience](./samples/getting_started/04-kernel-arguments-chat.ipynb)
- [Building Memory with Embeddings](./samples/getting_started/05-memory-and-embeddings.ipynb)
- [Using Hugging Face for Plugins](./samples/getting_started/06-hugging-face-for-plugins.ipynb)
- [Combining native functions and semantic functions](./samples/getting_started/07-native-function-inline.ipynb)
- [Groundedness Checking with Semantic Kernel](./samples/getting_started/08-groundedness-checking.ipynb)
- [Returning multiple results per prompt](./samples/getting_started/09-multiple-results-per-prompt.ipynb)
- [Streaming completions with Semantic Kernel](./samples/getting_started/10-streaming-completions.ipynb)

# SK Frequently Asked Questions

## How does Python SK compare to the C# version of Semantic Kernel?

The two SDKs are compatible and at their core they follow the same design principles.
Some features are still available only in the C# version and are being ported.
Refer to the [FEATURE MATRIX](../FEATURE_MATRIX.md) doc to see where
things stand in matching the features and functionality of the main SK branch.
Over time there will be some features available only in the Python version, and
others only in the C# version, for example, adapters to external services,
scientific libraries, etc.

